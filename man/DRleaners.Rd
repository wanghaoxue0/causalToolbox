% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DRRF.R
\name{DR-Learner}
\alias{DR-Learner}
\alias{DR_RF}
\title{DR-Learners}
\usage{
DR_RF(
  feat,
  tr,
  yobs,
  predmode = "propmean",
  nthread = 0,
  verbose = FALSE,
  trunc_level = 0.02,
  prop.forestry = list(relevant.Variable = 1:ncol(feat), ntree = 500, replace = TRUE,
    sample.fraction = 0.5, mtry = ncol(feat), nodesizeSpl = 11, nodesizeAvg = 33,
    nodesizeStrictSpl = 2, nodesizeStrictAvg = 1, splitratio = 1, middleSplit = FALSE,
    OOBhonest = TRUE),
  tau.forestry = list(relevant.Variable = 1:ncol(feat), ntree = 1000, replace = TRUE,
    sample.fraction = 0.7, mtry = round(ncol(feat) * 17/20), nodesizeSpl = 5, nodesizeAvg
    = 6, nodesizeStrictSpl = 3, nodesizeStrictAvg = 1, splitratio = 1, middleSplit =
    TRUE, OOBhonest = TRUE),
  mu.forestry = list(relevant.Variable = 1:ncol(feat), ntree = 1000, replace = TRUE,
    sample.fraction = 0.7, mtry = round(ncol(feat) * 17/20), nodesizeSpl = 5, nodesizeAvg
    = 6, nodesizeStrictSpl = 3, nodesizeStrictAvg = 1, splitratio = 1, middleSplit =
    TRUE, OOBhonest = TRUE),
  pseu.forestry = list(relevant.Variable = 1:ncol(feat), ntree = 1000, replace = TRUE,
    sample.fraction = 0.7, mtry = round(ncol(feat) * 17/20), nodesizeSpl = 5, nodesizeAvg
    = 6, nodesizeStrictSpl = 3, nodesizeStrictAvg = 1, splitratio = 1, middleSplit =
    TRUE, OOBhonest = TRUE)
)
}
\arguments{
\item{feat}{A data frame containing the features.}

\item{tr}{A numeric vector with 0 for control and 1 for treated variables.}

\item{yobs}{A numeric vector containing the observed outcomes.}

\item{predmode}{Specifies how the two estimators of the second stage should
be aggregated. Possible types are "propmean," "control," and "treated." The
default is "propmean," which refers to propensity score weighting.}

\item{nthread}{Number of threads which should be used to work in parallel.}

\item{verbose}{TRUE for detailed output, FALSE for no output.}

\item{trunc_level}{Level at which to truncate the estimated propensity scores
this ensures that the predicted propensity scores are bounded between
trunc_level < p_score < 1-trunc_level. Default is .02.}

\item{prop.forestry, tau.forestry, mu.forestry, pseu.forestry}{A list containing the
hyperparameters for the \code{Rforestry} package that are used for
estimating the response functions, the CATE, and the propensity score.
These hyperparameters are passed to the \code{Rforestry} package. (Please
refer to the \href{https://github.com/forestry-labs/Rforestry}{Rforestry}
package for a more detailed documentation of the hyperparamters.)
\itemize{
   \item \code{relevant.Variable} Variables that are only used in the first
         stage.
   \item \code{ntree} Numbers of trees used in the first stage.
   \item \code{replace} Sample with or without replacement in the first
         stage.
   \item \code{sample.fraction} The size of total samples to draw for the
         training data in the first stage.
   \item \code{mtry} The number of variables randomly selected in each
         splitting point.
   \item \code{nodesizeSpl} Minimum nodesize in the first stage for
         the observations in the splitting set. (See the details of the
         \code{forestry} package)
   \item \code{nodesizeAvg} Minimum nodesize in the first stage for
         the observations in the averaging set.
   \item \code{nodesizeStrictSpl} Minimum nodesize in the first stage for
         the observations in the splitting set. (See the details of the
         \code{forestry} package)
   \item \code{nodesizeStrictAvg} Minimum nodesize in the first stage for
         the observations in the averaging set.
   \item \code{splitratio} Proportion of the training data used as the
         splitting dataset in the first stage.
   \item \code{middleSplit} If true, the split value will be exactly in the
         middle of two observations. Otherwise, it will take a point
         based on a uniform distribution between the two observations.
   \item \code{OOBhonest} If true, forestry object will use the Out of Bag
         honesty implemented in the \code{Rforestry} package.
}}
}
\value{
An object from a class that contains the \code{CATEestimator}
  class. It should be used with one of the following functions:
  \code{EstimateCATE}, \code{CateCI}, and \code{CateBIAS}. The object has at least the
  following slots:
  \item{\code{feature_train}}{A copy of feat.}
  \item{\code{tr_train}}{A copy of tr.}
  \item{\code{yobs_train}}{A copy of yobs.}
  \item{\code{creator}}{Function call that creates the CATE estimator. This
  is used for different bootstrap procedures.}
}
\description{
DR_RF is an implementation of the DR-learner with Random Forests
  (Breiman 2001) as the base learners.
}
\examples{
require(causalToolbox)

# create example data set
simulated_experiment <- simulate_causal_experiment(
  ntrain = 1000,
  ntest = 1000,
  dim = 10
)
feat <- simulated_experiment$feat_tr
tr <- simulated_experiment$W_tr
yobs <- simulated_experiment$Yobs_tr
feature_test <- simulated_experiment$feat_te

# create the CATE estimator using Random Forests (RF)
xl_rf <- X_RF(feat = feat, tr = tr, yobs = yobs)
tl_rf <- T_RF(feat = feat, tr = tr, yobs = yobs)
sl_rf <- S_RF(feat = feat, tr = tr, yobs = yobs)
ml_rf <- M_RF(feat = feat, tr = tr, yobs = yobs)
xl_bt <- X_BART(feat = feat, tr = tr, yobs = yobs)
tl_bt <- T_BART(feat = feat, tr = tr, yobs = yobs)
sl_bt <- S_BART(feat = feat, tr = tr, yobs = yobs)
ml_bt <- M_BART(feat = feat, tr = tr, yobs = yobs)

cate_esti_xrf <- EstimateCate(xl_rf, feature_test)

# evaluate the performance.
cate_true <- simulated_experiment$tau_te
mean((cate_esti_xrf - cate_true) ^ 2)
\dontrun{
# create confidence intervals via bootstrapping.
xl_ci_rf <- CateCI(xl_rf, feature_test, B = 500)
}
}
\references{
\itemize{
  \item Edward Kennedy (2020).
    Optimal doubly robust estimation of heterogeneous causal effects.
    \url{https://arxiv.org/abs/2004.14497}
  }
}
\seealso{
Other metalearners: 
\code{\link{M-Learner}},
\code{\link{S-Learner}},
\code{\link{T-Learner}},
\code{\link{X-Learner}}
}
\author{
Soeren R. Kuenzel
}
\concept{metalearners}
